# SuperAnimal Behavior Analysis PoC

DeepLabCutì˜ [SuperAnimal](https://www.nature.com/articles/s41467-024-48792-2) ì‚¬ì „í›ˆë ¨ ëª¨ë¸ì„ í™œìš©í•œ ë™ë¬¼ í–‰ë™ ë¶„ì„ PoC (Proof of Concept) í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## Quick Start - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

### í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

`./run_all.sh`ì™€ `python run_comprehensive.py`ëŠ” ë™ì¼í•œ ì˜µì…˜ì„ ì§€ì›í•©ë‹ˆë‹¤.

```bash
# 1. í™˜ê²½ ì„¤ì¹˜
conda env create -f environment.yml
conda activate superanimal-poc

# 2. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (~2ë¶„)
./run_all.sh --debug
# ë˜ëŠ”
./run_all.sh -d

# 3. â­ ëª¨ë“  ì¡°í•© ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (~5ë¶„) - ì¶”ì²œ!
./run_all.sh --debug-full
# ë˜ëŠ”
./run_all.sh -df

# 4. í‘œì¤€ ë¶„ì„ (~10ë¶„, ê¸°ë³¸ê°’)
./run_all.sh

# 5. ì™„ì „í•œ ë¶„ì„ (~30ë¶„)
./run_all.sh --all
# ë˜ëŠ”
./run_all.sh -a
```

### ì»¤ìŠ¤í…€ ì„¤ì •

```bash
# íŠ¹ì • ì¢…ë§Œ ë¶„ì„
./run_all.sh --species mouse,dog

# íŠ¹ì • í”„ë¦¬ì…‹ë§Œ ì‚¬ìš©
./run_all.sh --presets full,standard,minimal

# í”„ë ˆì„ ìˆ˜ ì œí•œ
./run_all.sh --all --max-frames 100

# ì¡°í•© ì‚¬ìš©
./run_all.sh --species mouse,dog,horse --presets full,minimal --max-frames 50

# ê¸°ì¡´ ê²°ê³¼ì—ì„œ ì‹œê°í™”ë§Œ ì¬ìƒì„±
./run_all.sh --visualize-only --input outputs/comprehensive/20241127_123456

# ìƒì„¸ ë¡œê·¸ ì¶œë ¥
./run_all.sh --debug-full --verbose
```

### ì‹¤í–‰ ëª¨ë“œ ë¹„êµí‘œ

| ëª¨ë“œ | ëª…ë ¹ì–´ | í”„ë ˆì„ | ì¢… | í”„ë¦¬ì…‹ | ëª¨ë¸ | ì‹œê°„ |
|------|--------|--------|-----|--------|------|------|
| **Debug** | `-d`, `--debug` | 50 | 1 (mouse) | 2ê°œ | SuperAnimal | ~2ë¶„ |
| **Debug-Full** â­ | `-df`, `--debug-full` | 20 | 3ì¢… ëª¨ë‘ | 5ê°œ ëª¨ë‘ | ëª¨ë“  ëª¨ë¸ | ~5ë¶„ |
| **Standard** | (ê¸°ë³¸) | 200 | 2 (mouse, dog) | 3ê°œ | SuperAnimal | ~10ë¶„ |
| **Full** | `-a`, `--all` | 300 | 3ì¢… ëª¨ë‘ | 5ê°œ ëª¨ë‘ | ëª¨ë“  ëª¨ë¸ | ~30ë¶„ |

### ì‹¤í—˜ ê²°ê³¼ í™•ì¸

```bash
# ê²°ê³¼ ë””ë ‰í† ë¦¬ êµ¬ì¡°
outputs/full_pipeline/<timestamp>/
â”œâ”€â”€ experiment_results/          # ì‹¤í—˜ë³„ ê²°ê³¼
â”‚   â”œâ”€â”€ single_video_mouse/      # GIF, HTML ë³´ê³ ì„œ
â”‚   â”œâ”€â”€ keypoint_comparison/     # í”„ë¦¬ì…‹ ë¹„êµ GIF
â”‚   â””â”€â”€ cross_species/           # ì¢…ê°„ ë¹„êµ
â”œâ”€â”€ visualizations/              # ğŸ“Š ì‹œê°í™” ëª¨ìŒ
â”‚   â”œâ”€â”€ keypoint_comparison/     # í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ ì°¨íŠ¸
â”‚   â”‚   â”œâ”€â”€ performance_metrics.json   # ğŸ†• Accuracy/F1 ë©”íŠ¸ë¦­ (JSON)
â”‚   â”‚   â””â”€â”€ *_performance.png          # ğŸ†• ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
â”‚   â”œâ”€â”€ species_comparison/      # ì¢…ê°„ ë¹„êµ ì°¨íŠ¸
â”‚   â””â”€â”€ action_performance/      # ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
â”œâ”€â”€ comprehensive/               # (-c í”Œë˜ê·¸ ì‚¬ìš© ì‹œ)
â”‚   â”œâ”€â”€ all_species_comparison/  # 3ì¢… ë¹„êµ ê²°ê³¼
â”‚   â””â”€â”€ preset_*/                # ê° í”„ë¦¬ì…‹ë³„ ê²°ê³¼
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ baseline_comparison.json # ì •ëŸ‰ ë©”íŠ¸ë¦­ (Accuracy, F1, etc.)
â”œâ”€â”€ report/
â”‚   â””â”€â”€ dashboard.html           # ğŸ“ˆ ì¢…í•© ëŒ€ì‹œë³´ë“œ (ì¸í„°ë™í‹°ë¸Œ)
â”œâ”€â”€ summary.json                 # ì „ì²´ ìš”ì•½
â””â”€â”€ final_dashboard.html         # ğŸ¯ ìµœì¢… ëŒ€ì‹œë³´ë“œ (ë¸Œë¼ìš°ì € ìë™ ì˜¤í”ˆ)
```

### ëŒ€ì‹œë³´ë“œ ì§ì ‘ ì—´ê¸°

```bash
# macOS
open outputs/full_pipeline/<timestamp>/final_dashboard.html

# Linux
xdg-open outputs/full_pipeline/<timestamp>/final_dashboard.html

# Windows
start outputs/full_pipeline/<timestamp>/final_dashboard.html
```

---

## ì£¼ìš” ê¸°ëŠ¥

- **ë‹¤ì¤‘ ì…ë ¥ ì§€ì›**: ë¹„ë””ì˜¤ íŒŒì¼ ë˜ëŠ” ì´ë¯¸ì§€ ì‹œí€€ìŠ¤
- **Cross-Species ë¹„êµ**: Mouse, Dog, Horse ë“± ì—¬ëŸ¬ ì¢… ë™ì‹œ ë¶„ì„
- **Body Size ì¶”ì •**: ì¢…ë³„ ì²´í¬ í¬ê¸° ì •ëŸ‰í™” ë° ë¹„êµ
- **HTML ë³´ê³ ì„œ**: ëŒ€í™”í˜• ë³´ê³ ì„œ + Action GIF ì• ë‹ˆë©”ì´ì…˜
- **GPU ê°€ì†**: CUDA (Linux/Windows) ë° MPS (Apple Silicon) ì§€ì›
- **Hierarchical Action Comparison**: í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ë³„ action label ì„±ëŠ¥ ê³„ì¸µ ë¹„êµ

## ì§€ì› í”Œë«í¼

| í”Œë«í¼ | GPU ì§€ì› | í…ŒìŠ¤íŠ¸ ìƒíƒœ |
|--------|----------|-------------|
| **macOS (Apple Silicon)** | MPS | Supported |
| **macOS (Intel)** | CPU only | Supported |
| **Linux** | CUDA | Supported |
| **Windows** | CUDA | Supported |

GPU ìë™ ê°ì§€:
```bash
python run.py device=auto  # ìë™ ê°ì§€ (CUDA > MPS > CPU)
python run.py device=mps   # Apple Silicon GPU ê°•ì œ
python run.py device=cuda  # NVIDIA GPU ê°•ì œ
python run.py device=cpu   # CPU ê°•ì œ
```

## 3-Stage Pipeline

| Stage | ê¸°ëŠ¥ | ì‹¤í–‰ ëª…ë ¹ |
|-------|------|----------|
| **Stage 1** | ë™ë¬¼ í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ + í–‰ë™ ë¶„ì„ + HTML ë³´ê³ ì„œ | `python run.py` |
| **Stage 2** | í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ (Full/Standard/Minimal) | `python run_keypoint_comparison.py` |
| **Stage 3** | Cross-Species í–‰ë™ + Body Size ë¹„êµ | `python run_cross_species.py` |
| **Batch** | ì „ì²´ ì‹¤í—˜ + ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ | `./run_all.sh` |

---

## ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì¹˜

```bash
cd superanimal-behavior-poc
conda env create -f environment.yml
conda activate superanimal-poc

# (ì„ íƒ) ì¸ê°„ í¬ì¦ˆ ì¶”ì •ìš©
pip install mediapipe
```

### 2. Stageë³„ ì‹¤í–‰

```bash
# Stage 1: ê¸°ë³¸ ë™ë¬¼ í–‰ë™ ë¶„ì„ + HTML ë³´ê³ ì„œ
python run.py data.video.max_frames=100

# Stage 2: í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ ë³´ê³ ì„œ
python run_keypoint_comparison.py data.video.max_frames=100

# Stage 3: Cross-Species ë¹„êµ (mouse + dog)
python run_cross_species.py data.video.max_frames=100

# Stage 3: 3ì¢… ë¹„êµ (zshì—ì„œëŠ” ë”°ì˜´í‘œ í•„ìˆ˜)
python run_cross_species.py "species=[mouse,dog,horse]" data.video.max_frames=50
```

### 3. ì»¤ìŠ¤í…€ ì…ë ¥

```bash
# ë¹„ë””ì˜¤ íŒŒì¼
python run.py input=/path/to/my/video.mp4

# ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (íŒŒì¼ëª… ìˆ«ì ê¸°ì¤€ ì •ë ¬)
python run.py input=/path/to/frames/
# ì˜ˆ: frame_001.jpg, frame_002.jpg, ... ìˆœì„œë¡œ ì²˜ë¦¬
```

---

## Stage 1: Animal Keypoint & Behavior Analysis

ë™ë¬¼ ë¹„ë””ì˜¤ì—ì„œ í‚¤í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  í–‰ë™ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.

### ì‹¤í–‰

```bash
# ê¸°ë³¸ ì‹¤í–‰ (ìƒ˜í”Œ ë¹„ë””ì˜¤ ìë™ ë‹¤ìš´ë¡œë“œ)
python run.py

# í”„ë ˆì„ ì œí•œ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
python run.py data.video.max_frames=100

# Quadruped ëª¨ë¸ (ê°œ, ê³ ì–‘ì´ ë“±)
python run.py model=quadruped

# Video adaptation (ë” ì •í™•, ë” ëŠë¦¼)
python run.py model.video_adapt=true

# HTML ë³´ê³ ì„œ + Action GIF ìƒì„±
python run.py report.html=true report.gifs=true

# GPU ì¥ì¹˜ ì§€ì •
python run.py device=mps    # Apple Silicon
python run.py device=cuda   # NVIDIA GPU
python run.py device=cpu    # CPU only
```

### ì¶œë ¥

```
outputs/experiments/{timestamp}_{model}/
â”œâ”€â”€ report_{video}.html           # HTML ë³´ê³ ì„œ (ëŒ€í™”í˜•)
â”œâ”€â”€ gifs/                         # Actionë³„ GIF ì• ë‹ˆë©”ì´ì…˜
â”‚   â”œâ”€â”€ video_walking_1.gif
â”‚   â”œâ”€â”€ video_running_1.gif
â”‚   â””â”€â”€ video_resting_1.gif
â”œâ”€â”€ predictions/
â”‚   â”œâ”€â”€ *.h5                      # í‚¤í¬ì¸íŠ¸ (DLC í˜•ì‹)
â”‚   â”œâ”€â”€ keypoints_coordinates.csv # í‚¤í¬ì¸íŠ¸ (CSV)
â”‚   â””â”€â”€ *_labeled.mp4             # ë ˆì´ë¸” ë¹„ë””ì˜¤
â”œâ”€â”€ keypoint_frames/              # í‚¤í¬ì¸íŠ¸ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€
â”œâ”€â”€ videos/
â”‚   â””â”€â”€ *_keypoints.mp4           # ì˜¤ë²„ë ˆì´ ë¹„ë””ì˜¤
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ trajectory.png            # ì´ë™ ê¶¤ì 
â”‚   â”œâ”€â”€ velocity_profile.png      # ì†ë„ í”„ë¡œíŒŒì¼
â”‚   â”œâ”€â”€ behavior_timeline.png     # í–‰ë™ íƒ€ì„ë¼ì¸
â”‚   â””â”€â”€ analysis_report.png       # ì¢…í•© ë³´ê³ ì„œ
â”œâ”€â”€ behavior_metrics.csv          # í”„ë ˆì„ë³„ í–‰ë™ ë°ì´í„°
â””â”€â”€ .hydra/                       # Hydra ì„¤ì • ë¡œê·¸
```

### ì§€ì› ëª¨ë¸

| ëª¨ë¸ | ì„¤ëª… | í‚¤í¬ì¸íŠ¸ | ëŒ€ìƒ |
|------|------|----------|------|
| SuperAnimal-TopViewMouse | ìƒë‹¨ ë·° | 27ê°œ | ìƒì¥, ì¥ |
| SuperAnimal-Quadruped | ì¸¡ë©´ ë·° | 39ê°œ | ê°œ, ê³ ì–‘ì´, ë§ ë“± 45+ ì¢… |

---

## Stage 2: Keypoint Preset Comparison

ë™ì¼ ë¹„ë””ì˜¤ì— ë‹¤ì–‘í•œ í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ì„ ì ìš©í•˜ì—¬ ë¹„êµí•©ë‹ˆë‹¤.

### ì‹¤í–‰

```bash
# ê¸°ë³¸ ì‹¤í–‰
python run_keypoint_comparison.py

# í”„ë ˆì„ ì œí•œ
python run_keypoint_comparison.py data.video.max_frames=100
```

### í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹

| í”„ë¦¬ì…‹ | ê°œìˆ˜ | ìš©ë„ |
|--------|------|------|
| **Full** | 27 | ì •ë°€ ìì„¸ ë¶„ì„, ê·¸ë£¨ë° ê°ì§€ |
| **Standard** | 11 | Open Field Test, ì¼ë°˜ í–‰ë™ |
| **MARS** | 7 | ì‚¬íšŒì  ìƒí˜¸ì‘ìš©, ë‹¤ì¤‘ ë™ë¬¼ |
| **Locomotion** | 5 | ì´ë™/ë³´í–‰ ë¶„ì„ |
| **Minimal** | 3 | ê¸°ë³¸ ì¶”ì , ì‹¤ì‹œê°„ ì²˜ë¦¬ |

### Action Recognition ì„±ëŠ¥ ë¹„êµ (Accuracy/F1)

í‚¤í¬ì¸íŠ¸ ìˆ˜ì— ë”°ë¥¸ action recognition ì„±ëŠ¥ ì°¨ì´ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.
**Full í”„ë¦¬ì…‹(27ê°œ)ì„ ê¸°ì¤€(ground truth)ìœ¼ë¡œ** ê° í”„ë¦¬ì…‹ì˜ accuracy, F1 scoreë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.

```
=== Performance by Keypoint Count ===
Preset      | Keypoints | Accuracy | Agreement | Mean F1
------------|-----------|----------|-----------|--------
Full        | 27        | 100.0%   | 100.0%    | 1.000
Standard    | 11        | 95.2%    | 95.2%     | 0.948
MARS        | 7         | 91.8%    | 91.8%     | 0.912
Locomotion  | 5         | 88.5%    | 88.5%     | 0.879
Minimal     | 3         | 82.3%    | 82.3%     | 0.815
```

ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸ ê°€ëŠ¥:
- **Accuracy by Preset**: ê° í”„ë¦¬ì…‹ë³„ ì •í™•ë„ ë§‰ëŒ€ ê·¸ë˜í”„
- **F1 by Action Class**: stationary, walking, running ë³„ F1 ì ìˆ˜
- **Keypoint Count vs Accuracy**: í‚¤í¬ì¸íŠ¸ ìˆ˜ì™€ ì •í™•ë„ ê´€ê³„ (íŠ¸ë Œë“œ ë¼ì¸ í¬í•¨)
- **Accuracy Drop from Full**: Full ëŒ€ë¹„ ì •í™•ë„ í•˜ë½ë¥ 

### Hierarchical Action Label Comparison (NEW)

Action label ë³„ë¡œ í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ì„±ëŠ¥ì„ ê³„ì¸µì ìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤:

**ì‹œê°í™” ì¶œë ¥:**
1. **hierarchical_action_comparison.png**: 3ë‹¨ ê³„ì¸µì  ë¹„êµ ì°¨íŠ¸
   - Row 1: Overall accuracy, Mean F1, Keypoint-Accuracy trade-off
   - Row 2: Per-action breakdown (stationary, walking, runningì˜ F1/Precision/Recall)
   - Row 3: F1 Heatmap (action x preset) + Summary table

2. **confusion_matrix_grid.png**: ê° í”„ë¦¬ì…‹ë³„ Confusion Matrix
   - Full presetì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ í”„ë¦¬ì…‹ì˜ action ë¶„ë¥˜ ì˜¤ì°¨ ì‹œê°í™”
   - ì •ê·œí™”ëœ ë¹„ìœ¨ + ì‹¤ì œ count í‘œì‹œ

```
outputs/visualizations/keypoint_comparison/
â”œâ”€â”€ performance_by_keypoint_*.png     # ê¸°ë³¸ ì„±ëŠ¥ ë¹„êµ
â”œâ”€â”€ hierarchical_action_comparison_*.png  # ê³„ì¸µì  action ë¹„êµ
â”œâ”€â”€ confusion_matrix_grid_*.png       # Confusion matrix ê·¸ë¦¬ë“œ
â””â”€â”€ performance_metrics.json          # JSON ë©”íŠ¸ë¦­ ë°ì´í„°
```

---

## Stage 3: Cross-Species Action Recognition

ì—¬ëŸ¬ ì¢…ì˜ ê³µí†µ í–‰ë™(walking, running, stationary)ê³¼ Body Sizeë¥¼ ë¹„êµ ë¶„ì„í•©ë‹ˆë‹¤.

### ì‹¤í–‰

```bash
# ê¸°ë³¸ ì‹¤í–‰ (mouse + dog)
python run_cross_species.py data.video.max_frames=100

# 3ì¢… ë¹„êµ (zshì—ì„œëŠ” ë”°ì˜´í‘œ í•„ìˆ˜!)
python run_cross_species.py "species=[mouse,dog,horse]" data.video.max_frames=50

# 2ì¢…ë§Œ ë¹„êµ
python run_cross_species.py "species=[mouse,horse]"
```

### ì§€ì› ì¢…

| ì¢… | Sample | Model Type | ì„¤ëª… |
|----|--------|------------|------|
| mouse | mouse_topview | topviewmouse | ìƒì¥ (ìƒë‹¨ ë·°) |
| dog | dog_walking | quadruped | ê°œ (ì¸¡ë©´ ë·°) |
| horse | horse_running | quadruped | ë§ (ì¸¡ë©´ ë·°) |

### ì¶œë ¥

```
outputs/experiments/cross_species_{timestamp}/
â”œâ”€â”€ cross_species_report.html     # HTML ë¹„êµ ë³´ê³ ì„œ
â”œâ”€â”€ cross_species_comparison.png  # ì‹œê°í™” ë¹„êµ (4-panel)
â”‚   â”œâ”€â”€ Action Distribution       # í–‰ë™ ë¶„í¬ ë¹„êµ
â”‚   â”œâ”€â”€ Velocity Profile          # ì •ê·œí™” ì†ë„ ë¹„êµ
â”‚   â”œâ”€â”€ Body Size Bar Chart       # Body Size ë§‰ëŒ€ ê·¸ë˜í”„
â”‚   â””â”€â”€ Body Size Box Plot        # Body Size ë¶„í¬
â”œâ”€â”€ action_comparison.csv         # í–‰ë™ ë¶„í¬ CSV
â”œâ”€â”€ mouse_predictions/
â”œâ”€â”€ dog_predictions/
â””â”€â”€ horse_predictions/
```

### Body Size ì¶”ì •

ê° ì¢…ì˜ body sizeë¥¼ í‚¤í¬ì¸íŠ¸ ê°„ ê±°ë¦¬(ë¨¸ë¦¬-ê¼¬ë¦¬)ë¡œ ì¶”ì •í•©ë‹ˆë‹¤:

```
=== Body Size Comparison ===
Mouse: 114.0 Â± 12.5 px (range: 95.2-132.8)
Dog:   245.3 Â± 18.7 px (range: 210.5-278.9)
Horse: 320.1 Â± 25.2 px (range: 285.0-365.4)
```

ì†ë„ëŠ” body-length/secë¡œ ì •ê·œí™”ë˜ì–´ ì¢… ê°„ ê³µì •í•œ ë¹„êµê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## Action GIF ì‹œê°í™”

ê° í–‰ë™ ìœ í˜•ë³„ë¡œ RGB + Keypoint overlay ì• ë‹ˆë©”ì´ì…˜ GIFë¥¼ ìƒì„±í•˜ì—¬ detection ì •í™•ë„ë¥¼ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### í™œì„±í™”

```bash
# HTML ë³´ê³ ì„œ + Action GIF ìƒì„±
python run.py report.html=true report.gifs=true

# GIF ì„¤ì • ì¡°ì •
python run.py report.gifs=true report.gifs_per_action=3 report.gif_fps=10
```

### GIF ì¶œë ¥

```
outputs/experiments/{timestamp}/gifs/
â”œâ”€â”€ video_resting_1.gif     # ì •ì§€ ìƒíƒœ ìƒ˜í”Œ 1
â”œâ”€â”€ video_resting_2.gif     # ì •ì§€ ìƒíƒœ ìƒ˜í”Œ 2
â”œâ”€â”€ video_walking_1.gif     # ê±·ê¸° ìƒ˜í”Œ 1
â”œâ”€â”€ video_walking_2.gif     # ê±·ê¸° ìƒ˜í”Œ 2
â”œâ”€â”€ video_running_1.gif     # ë‹¬ë¦¬ê¸° ìƒ˜í”Œ 1
â””â”€â”€ video_running_2.gif     # ë‹¬ë¦¬ê¸° ìƒ˜í”Œ 2
```

ê° GIFì—ëŠ”:
- RGB ì˜ìƒ í”„ë ˆì„
- Keypoint ì˜¤ë²„ë ˆì´ (ìƒ‰ìƒ êµ¬ë¶„)
- Skeleton ì—°ê²°ì„ 
- Action ë¼ë²¨ í‘œì‹œ
- í”„ë ˆì„ ë²ˆí˜¸

### HTML ë³´ê³ ì„œ í†µí•©

ìƒì„±ëœ GIFëŠ” HTML ë³´ê³ ì„œì— ìë™ìœ¼ë¡œ ì‚½ì…ë˜ì–´ ê° actionë³„ë¡œ ê°¤ëŸ¬ë¦¬ í˜•íƒœë¡œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ì„¤ì •

### config.yaml ì£¼ìš” ì„¤ì •

```yaml
# ì¥ì¹˜ ì„¤ì •
device: auto  # auto, cuda, mps, cpu

# ì…ë ¥ (ì„ íƒì‚¬í•­)
input: null  # ë¹„ë””ì˜¤ íŒŒì¼ ë˜ëŠ” ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ

# Cross-species ì¢… ëª©ë¡
species:
  - mouse
  - dog

# ë³´ê³ ì„œ ì„¤ì •
report:
  html: true          # HTML ë³´ê³ ì„œ ìƒì„±
  gifs: true          # Action GIF ìƒì„±
  gifs_per_action: 2  # ì•¡ì…˜ë‹¹ GIF ìˆ˜
  gif_fps: 8          # GIF í”„ë ˆì„ë ˆì´íŠ¸

# ë¹„ë””ì˜¤ ì²˜ë¦¬
data:
  video:
    max_frames: 500   # ìµœëŒ€ í”„ë ˆì„ (null = ì „ì²´)
```

### í–‰ë™ ë¶„ë¥˜ ì„ê³„ê°’

```yaml
# configs/behavior/default.yaml
analysis:
  classification:
    behaviors:
      - name: resting
        velocity_threshold: 0.3
      - name: walking
        velocity_threshold_min: 0.3
        velocity_threshold_max: 3.0
```

---

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
superanimal-behavior-poc/
â”œâ”€â”€ run.py                  # Stage 1: ê¸°ë³¸ í–‰ë™ ë¶„ì„
â”œâ”€â”€ run_comparison.py       # Stage 2: í‚¤í¬ì¸íŠ¸ ë¹„êµ
â”œâ”€â”€ run_cross_species.py    # Stage 3: Cross-species ë¹„êµ
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml         # ë©”ì¸ ì„¤ì •
â”‚   â”œâ”€â”€ model/              # topviewmouse.yaml, quadruped.yaml
â”‚   â”œâ”€â”€ data/
â”‚   â””â”€â”€ behavior/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ predictor.py        # SuperAnimal ë˜í¼ (ë¹„ë””ì˜¤/ì´ë¯¸ì§€)
â”‚   â”‚   â””â”€â”€ action_classifier.py # Cross-species ë¶„ë¥˜ê¸°
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ behavior.py         # í–‰ë™ ë¶„ì„ + Body Size ì¶”ì •
â”‚   â”‚   â”œâ”€â”€ visualizer.py       # ì‹œê°í™”
â”‚   â”‚   â””â”€â”€ report_generator.py # HTML ë³´ê³ ì„œ + GIF ìƒì„±
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ downloader.py       # ìƒ˜í”Œ ë‹¤ìš´ë¡œë“œ
â”‚   â”‚   â””â”€â”€ human_pose.py       # MediaPipe ë˜í¼
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ setup.sh            # í™˜ê²½ ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ download_samples.py # ìƒ˜í”Œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
â”‚   â”‚   â””â”€â”€ download_datasets.py # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ DATASETS.md             # ë°ì´í„°ì…‹ ê°€ì´ë“œ
â”‚   â”œâ”€â”€ keypoint_paradigms.md
â”‚   â””â”€â”€ custom_dataset_guide.md
â”œâ”€â”€ data/                   # ì…ë ¥ ë°ì´í„° (git ignored)
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ external/
â”œâ”€â”€ outputs/                # ì¶œë ¥ ê²°ê³¼ (git ignored)
â”‚   â”œâ”€â”€ experiments/        # ì‹¤í—˜ ê²°ê³¼
â”‚   â””â”€â”€ logs/               # Hydra ë¡œê·¸
â””â”€â”€ environment.yml         # Conda í™˜ê²½
```

---

## Python API

### ë¹„ë””ì˜¤/ì´ë¯¸ì§€ ì¶”ë¡ 

```python
from src.models.predictor import SuperAnimalPredictor

predictor = SuperAnimalPredictor(
    model_type="topviewmouse",
    device="auto",  # auto, cuda, mps, cpu
)

# ë¹„ë””ì˜¤ ì¶”ë¡ 
results = predictor.predict_video(
    video_path="video.mp4",
    output_dir="output",
    max_frames=100,
)

# ì´ë¯¸ì§€ ì¶”ë¡ 
results = predictor.predict_images(
    image_paths=["frame1.jpg", "frame2.jpg"],
    output_dir="output",
)

keypoints = results["keypoints"]  # Shape: (frames, keypoints, 3)
```

### Body Size ì¶”ì •

```python
from src.analysis.behavior import estimate_body_size

body_stats = estimate_body_size(
    keypoints=results["keypoints"],
    keypoint_names=predictor.get_keypoint_names(),
    model_type="topviewmouse",
)

print(f"Body size: {body_stats['mean']:.1f} Â± {body_stats['std']:.1f} px")
```

### HTML ë³´ê³ ì„œ ìƒì„±

```python
from src.analysis.report_generator import HTMLReportGenerator, ActionGifGenerator

# GIF ìƒì„±
gif_gen = ActionGifGenerator(output_dir="gifs")
action_gifs = gif_gen.generate_all_action_gifs(
    video_path="video.mp4",
    keypoints=keypoints,
    keypoint_names=names,
    action_labels=metrics.behavior_labels,
    action_names={0: "resting", 1: "walking", 2: "running"},
)

# HTML ë³´ê³ ì„œ
html_gen = HTMLReportGenerator(output_dir="reports")
html_gen.generate_behavior_report(
    video_name="my_video",
    species="mouse",
    metrics={"behavior_summary": metrics.behavior_summary},
    action_gifs=action_gifs,
    plot_paths={"trajectory": "plots/trajectory.png"},
    body_size_stats=body_stats,
)
```

### Cross-Species ë¹„êµ

```python
from src.models.action_classifier import UnifiedActionClassifier, CrossSpeciesComparator

comparator = CrossSpeciesComparator(fps=30.0)

# ê° ì¢… ë¶„ì„
for species in ["mouse", "dog"]:
    classifier = UnifiedActionClassifier(species=species, fps=30.0)
    metrics = classifier.analyze(keypoints, keypoint_names)
    comparator.add_result(species.capitalize(), metrics)

# ë¹„êµ ê²°ê³¼ ì €ì¥
comparator.save_comparison_csv("comparison.csv")
```

### Keypoint Preset ì„±ëŠ¥ ë¹„êµ (Accuracy/F1)

```python
from src.analysis.keypoint_visualizer import (
    KeypointVisualizer,
    compare_presets_with_metrics,
)

# Full presetì„ referenceë¡œ ê° í”„ë¦¬ì…‹ë³„ accuracy/F1 ê³„ì‚°
presets = ["full", "standard", "mars", "locomotion", "minimal"]
results, metrics = compare_presets_with_metrics(
    keypoints=keypoints,           # (frames, keypoints, 3)
    all_keypoint_names=names,      # ì „ì²´ í‚¤í¬ì¸íŠ¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    presets=presets,
    fps=30.0,
    reference_preset="full",       # Ground truthë¡œ ì‚¬ìš©í•  í”„ë¦¬ì…‹
)

# ê²°ê³¼ í™•ì¸
for r in results:
    print(f"{r.preset_name}: accuracy={r.accuracy:.3f}, agreement={r.agreement_with_full:.3f}")
    print(f"  F1 scores: {r.f1_scores}")

# ì‹œê°í™” ìƒì„±
viz = KeypointVisualizer(output_dir="outputs/keypoint_comparison")
viz.create_performance_by_keypoint_count(results, video_name="my_video")
```

ì¶œë ¥ ì˜ˆì‹œ:
```
full: accuracy=1.000, agreement=1.000
  F1 scores: {'stationary': 1.0, 'walking': 1.0, 'running': 1.0}
standard: accuracy=0.952, agreement=0.952
  F1 scores: {'stationary': 0.96, 'walking': 0.94, 'running': 0.93}
minimal: accuracy=0.823, agreement=0.823
  F1 scores: {'stationary': 0.85, 'walking': 0.80, 'running': 0.78}
```

---

## ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ

### ìƒ˜í”Œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ

```bash
# ëª¨ë“  ìƒ˜í”Œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ (mouse, dog, horse)
python -m src.scripts.download_samples

# ë˜ëŠ” ê°œë³„ ë‹¤ìš´ë¡œë“œ
python -m src.scripts.download_datasets --samples
```

### ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹

```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì…‹ ëª©ë¡
python -m src.scripts.download_datasets --list

# íŠ¹ì • ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì•ˆë‚´
python -m src.scripts.download_datasets --dataset mars
python -m src.scripts.download_datasets --dataset ap10k
python -m src.scripts.download_datasets --dataset coco_pose
```

### ì§€ì› ë°ì´í„°ì…‹

| ë°ì´í„°ì…‹ | ì¢… | í‚¤í¬ì¸íŠ¸ | ìš©ë„ |
|----------|-----|----------|------|
| **Sample Videos** | mouse, dog, horse | 27/39 | ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ |
| **MARS** | mouse (Ã—2) | 7 | ì‚¬íšŒì  ìƒí˜¸ì‘ìš©, í–‰ë™ ë¶„ë¥˜ |
| **AP-10K** | 60+ ì¢… | 17 | ë‹¤ì¢… ë™ë¬¼ í¬ì¦ˆ |
| **COCO** | human | 17 | ì¸ê°„ í¬ì¦ˆ ì¶”ì • |
| **UCLA Mouse** | mouse | - | í–‰ë™ ì¸ì‹ ë°ëª¨ |

---

## ë¬¸ì„œ

- [ì´ë¡ ì  ë°°ê²½ ë° íŒŒì´í”„ë¼ì¸ êµ¬ì¡°](docs/theory_and_pipeline.md) - **í•µì‹¬ ì´ë¡ , ëª¨ë“ˆ ì„¤ëª…**
- [ì•„í‚¤í…ì²˜ ê°€ì´ë“œ](docs/architecture.md) - ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì¡°
- [ì„¤ì • ê°€ì´ë“œ](docs/configuration.md) - ëª¨ë“  ì„¤ì • ì˜µì…˜
- [ë°ì´í„°ì…‹ ê°€ì´ë“œ](docs/DATASETS.md) - ì¸ê¸° pose estimation ë°ì´í„°ì…‹
- [í‚¤í¬ì¸íŠ¸ íŒ¨ëŸ¬ë‹¤ì„ ê°€ì´ë“œ](docs/keypoint_paradigms.md)
- [ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ & Fine-tuning ê°€ì´ë“œ](docs/custom_dataset_guide.md)

---

## Batch Experiment Pipeline

### ì „ì²´ ì‹¤í—˜ ìë™ ì‹¤í–‰

```bash
# ê¶Œì¥: Debug â†’ Full â†’ Model Comparison â†’ ì‹œê°í™” â†’ ëŒ€ì‹œë³´ë“œ
./run_all.sh

# Debugë§Œ (ë¹ ë¥¸ ê²€ì¦, ~2ë¶„)
./run_all.sh --debug-only
./run_all.sh -d

# Fullë§Œ (Debug ìŠ¤í‚µ, ~8ë¶„)
./run_all.sh --full-only
./run_all.sh -f

# Comprehensive ëª¨ë“œ (ëª¨ë“  ì¡°í•© ë¶„ì„, ~30ë¶„)
./run_all.sh --comprehensive
./run_all.sh -c

# Full + Comprehensive ì¡°í•© (ê¶Œì¥: ì™„ì „í•œ ë³´ê³ ì„œìš©)
./run_all.sh --full-only -c
```

### ì‹¤í–‰ ëª¨ë“œ ë¹„êµ

| ëª¨ë“œ | ëª…ë ¹ì–´ | ë‚´ìš© | ì˜ˆìƒ ì‹œê°„ |
|------|--------|------|-----------|
| **ê¸°ë³¸** | `./run_all.sh` | Debug â†’ Full â†’ Model Comparison â†’ ëŒ€ì‹œë³´ë“œ | ~10ë¶„ |
| **Debug Only** | `./run_all.sh -d` | ë¹ ë¥¸ ê²€ì¦ (50 frames), ì‹œê°í™” ìŠ¤í‚µ | ~2ë¶„ |
| **Full Only** | `./run_all.sh -f` | Debug ìŠ¤í‚µ, Full + ì‹œê°í™” + ëŒ€ì‹œë³´ë“œ | ~8ë¶„ |
| **Comprehensive** | `./run_all.sh -c` | ëª¨ë“  ì¢…/í”„ë¦¬ì…‹/ëª¨ë¸ + ì¢…í•© ëŒ€ì‹œë³´ë“œ | ~30ë¶„ |
| **Full + Comprehensive** | `./run_all.sh -f -c` | ê°€ì¥ ì™„ì „í•œ ë¶„ì„ ë° ë³´ê³ ì„œ | ~25ë¶„ |

### íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë‹¨ê³„

```
./run_all.sh -c ì‹¤í–‰ ì‹œ:

Step 1: Debug Mode (ì„ íƒì )
   â””â”€â”€ ë¹ ë¥¸ ê²€ì¦ í…ŒìŠ¤íŠ¸

Step 2: Full Experiments
   â”œâ”€â”€ Single Video Analysis (300 frames)
   â”œâ”€â”€ Keypoint Comparison (Full/Standard/Minimal)
   â””â”€â”€ Cross-Species (Mouse vs Dog)

Step 3: Comprehensive Analysis (-c í”Œë˜ê·¸ í•„ìš”)
   â”œâ”€â”€ All Species Comparison (Mouse, Dog, Horse)
   â””â”€â”€ All Keypoint Presets (5ê°œ í”„ë¦¬ì…‹ Ã— ë¶„ì„)

Step 4: Model Comparison
   â”œâ”€â”€ SuperAnimal vs YOLO Pose
   â””â”€â”€ Baseline ëª¨ë¸ ë¹„êµ

Step 5: Generate Visualizations â­ NEW
   â”œâ”€â”€ Keypoint Preset Comparison Charts
   â”œâ”€â”€ Species Comparison Charts
   â””â”€â”€ Action Performance Charts

Step 6: Generate Dashboard â­ NEW
   â””â”€â”€ Comprehensive HTML Dashboard (auto-open)
```

### Comprehensive ëª¨ë“œ ìƒì„¸

Comprehensive ëª¨ë“œ(`-c`)ëŠ” ê°€ëŠ¥í•œ ëª¨ë“  ì¡°í•©ì„ ë¶„ì„í•©ë‹ˆë‹¤:

| ë¶„ì„ í•­ëª© | ë‚´ìš© |
|-----------|------|
| **Species** | Mouse, Dog, Horse (3ì¢…) |
| **Keypoint Presets** | Full (27), Standard (11), MARS (7), Locomotion (5), Minimal (3) |
| **Models** | SuperAnimal, YOLO Pose, Baselines (Random, Majority, Threshold) |
| **ì´ ì¡°í•©** | 15ê°œ (3ì¢… Ã— 5í”„ë¦¬ì…‹) + ëª¨ë¸ ë¹„êµ |

**ìƒì„±ë˜ëŠ” ì‹œê°í™”:**

1. **í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ**
   - í‚¤í¬ì¸íŠ¸ ìˆ˜ë³„ Action Distribution ë³€í™”
   - í‚¤í¬ì¸íŠ¸ í¬í•¨ ë§¤íŠ¸ë¦­ìŠ¤ (ì–´ë–¤ í‚¤í¬ì¸íŠ¸ê°€ ì–´ë–¤ í”„ë¦¬ì…‹ì— í¬í•¨ë˜ëŠ”ì§€)
   - í”„ë¦¬ì…‹ë³„ GIF ì• ë‹ˆë©”ì´ì…˜ ë¹„êµ

2. **ì¢…ê°„ ë¹„êµ**
   - Body Size ë¹„êµ (bar chart, box plot, relative size)
   - Action Distribution by Species
   - Velocity Profile (body-length ì •ê·œí™”)
   - Comprehensive 4-panel ë¹„êµ ì°¨íŠ¸

3. **Action Recognition ì„±ëŠ¥**
   - ëª¨ë¸ë³„ Accuracy ë¹„êµ
   - F1 Score by Action Class (stationary/walking/running)
   - Consistency Score (ì‹œê°„ì  ì¼ê´€ì„±)

### í¬í•¨ëœ ì‹¤í—˜

| ì‹¤í—˜ | ì„¤ëª… | Debug | Full |
|------|------|-------|------|
| `single_video_mouse` | SuperAnimal-TopViewMouse ë¶„ì„ | 50 frames | 300 frames |
| `keypoint_comparison` | Full/Standard/Minimal ë¹„êµ GIF | 30 frames | 200 frames |
| `cross_species` | Mouse vs Dog í–‰ë™ ë¹„êµ | 50 frames | 200 frames |

### ëª¨ë¸ ë¹„êµ (Model Comparison)

ë‹¤ë¥¸ ìœ ëª… ëª¨ë¸ë“¤ê³¼ ë¹„êµí•©ë‹ˆë‹¤:

```bash
# ê°œë³„ ì‹¤í–‰
python run_model_comparison.py
python run_model_comparison.py --models superanimal,yolo_pose
```

| ëª¨ë¸ | ì„¤ëª… | ì„¤ì¹˜ |
|------|------|------|
| **SuperAnimal** | DeepLabCut 3.0 ì‚¬ì „í›ˆë ¨ ëª¨ë¸ (ê¸°ë³¸) | ê¸°ë³¸ í¬í•¨ |
| **YOLO Pose** | Ultralytics YOLOv8-pose | `pip install ultralytics` |
| **MMPose** | OpenMMLab ë™ë¬¼ í¬ì¦ˆ ì¶”ì • (ì„ íƒ) | `pip install mmpose` |

### ë² ì´ìŠ¤ë¼ì¸ ë¹„êµ

| Baseline | ì„¤ëª… |
|----------|------|
| **Random** | ëœë¤ í–‰ë™ ì˜ˆì¸¡ (40% stationary, 40% walking, 20% running) |
| **Majority** | ê°€ì¥ ë¹ˆë²ˆí•œ í´ë˜ìŠ¤ë¡œ ëª¨ë“  í”„ë ˆì„ ì˜ˆì¸¡ |
| **SimpleThreshold** | Body-size ì •ê·œí™” ì—†ì´ í”½ì…€ ì†ë„ë§Œ ì‚¬ìš© |
| **CentroidOnly** | ì „ì²´ í‚¤í¬ì¸íŠ¸ ëŒ€ì‹  ì¤‘ì‹¬ì ë§Œ ì‚¬ìš© |

### ì •ëŸ‰ ë©”íŠ¸ë¦­

**í‚¤í¬ì¸íŠ¸ ë©”íŠ¸ë¦­:**
- **PCK@0.1, PCK@0.2**: Percentage of Correct Keypoints (threshold ê¸°ì¤€)
- **OKS**: Object Keypoint Similarity (COCO í‘œì¤€ ë©”íŠ¸ë¦­)

**í–‰ë™ ì¸ì‹ ë©”íŠ¸ë¦­:**
- **Accuracy**: ì „ì²´ ì •í™•ë„
- **F1 Score**: í´ë˜ìŠ¤ë³„ F1
- **Agreement Rate**: ëª¨ë¸ ê°„ ì¼ì¹˜ìœ¨
- **Consistency Score**: ì‹œê°„ì  ì¼ê´€ì„± (ê¸‰ê²©í•œ ë³€í™” í˜ë„í‹°)

```
======================================================================
MODEL COMPARISON RESULTS
======================================================================

Reference Model: superanimal

ğŸ“Š Action Recognition Comparison:
--------------------------------------------------
Model                     Agreement   Accuracy   Consistency
--------------------------------------------------
yolo_pose                     72.3%      68.5%         0.85
random                        33.2%      33.2%         0.45
majority                      45.0%      45.0%         1.00
--------------------------------------------------

ğŸ“ Keypoint Detection Comparison:
--------------------------------------------------
Model                          OKS    PCK@0.1    PCK@0.2
--------------------------------------------------
yolo_pose                    0.652      0.485      0.723
--------------------------------------------------
```

### ëª¨ë“ˆ êµ¬ì¡°

```
run_all.sh                          # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì‹œê°í™” + ëŒ€ì‹œë³´ë“œ í¬í•¨)
â”œâ”€â”€ run.py                          # Stage 1: ë‹¨ì¼ ë¹„ë””ì˜¤ ë¶„ì„
â”œâ”€â”€ run_keypoint_comparison.py      # Stage 2: í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ
â”œâ”€â”€ run_cross_species.py            # Stage 3: ì¢…ê°„ ë¹„êµ
â”œâ”€â”€ run_model_comparison.py         # Step 4: ëª¨ë¸ ë¹„êµ (YOLO, Baselines)
â”œâ”€â”€ generate_report.py              # â­ Step 5-6: ì¢…í•© ëŒ€ì‹œë³´ë“œ ìƒì„±
â”‚
â”œâ”€â”€ src/models/
â”‚   â”œâ”€â”€ predictor.py           # SuperAnimal í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ
â”‚   â”œâ”€â”€ action_classifier.py   # í–‰ë™ ë¶„ë¥˜ (body-length ì •ê·œí™”)
â”‚   â”œâ”€â”€ baseline.py            # ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ë“¤ (Random, Majority, etc.)
â”‚   â””â”€â”€ yolo_pose.py           # YOLO Pose ë˜í¼
â”œâ”€â”€ src/evaluation/
â”‚   â”œâ”€â”€ metrics.py             # ì •ëŸ‰ í‰ê°€ (Accuracy, F1, Confusion Matrix)
â”‚   â””â”€â”€ model_comparison.py    # PCK, OKS ë©”íŠ¸ë¦­
â”œâ”€â”€ src/analysis/
â”‚   â”œâ”€â”€ behavior.py            # Body size ì¶”ì •
â”‚   â”œâ”€â”€ report_generator.py    # HTML ë³´ê³ ì„œ + GIF ìƒì„±
â”‚   â”œâ”€â”€ visualizer.py          # ì‹œê°í™”
â”‚   â”œâ”€â”€ dashboard.py           # â­ ì¢…í•© HTML ëŒ€ì‹œë³´ë“œ ìƒì„±
â”‚   â”œâ”€â”€ keypoint_visualizer.py # â­ í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ ì‹œê°í™”
â”‚   â””â”€â”€ species_visualizer.py  # â­ ì¢…ê°„ ë¹„êµ ì‹œê°í™”
â””â”€â”€ configs/
    â”œâ”€â”€ config.yaml            # ë©”ì¸ ì„¤ì •
    â”œâ”€â”€ model/                 # ëª¨ë¸ë³„ ì„¤ì • + í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹
    â””â”€â”€ species/               # ì¢…ë³„ velocity threshold
```

### ì‹œê°í™” ëª¨ë“ˆ ì‚¬ìš©ë²•

```python
# 1. í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ ë¹„êµ ì‹œê°í™”
from src.analysis.keypoint_visualizer import KeypointVisualizer, compare_presets

visualizer = KeypointVisualizer(output_dir="outputs/visualizations")

# í”„ë¦¬ì…‹ ë¹„êµ ì •ì  ì´ë¯¸ì§€
visualizer.create_preset_comparison_figure(
    video_path="video.mp4",
    keypoints=keypoints,
    all_keypoint_names=names,
    presets=["full", "standard", "minimal"],
)

# í”„ë¦¬ì…‹ ë¹„êµ GIF ì• ë‹ˆë©”ì´ì…˜
visualizer.create_comparison_gif(
    video_path="video.mp4",
    keypoints=keypoints,
    all_keypoint_names=names,
    presets=["full", "standard", "minimal"],
    max_frames=100,
    fps=8.0,
)

# 2. ì¢…ê°„ ë¹„êµ ì‹œê°í™”
from src.analysis.species_visualizer import SpeciesVisualizer, create_species_result

visualizer = SpeciesVisualizer(output_dir="outputs/visualizations")

# ì¢…ë³„ ê²°ê³¼ ìƒì„±
mouse_result = create_species_result("mouse", "topviewmouse", mouse_keypoints, mouse_names)
dog_result = create_species_result("dog", "quadruped", dog_keypoints, dog_names)

# ì¢…í•© ë¹„êµ ì°¨íŠ¸
visualizer.create_comprehensive_comparison([mouse_result, dog_result])

# 3. ì¢…í•© ëŒ€ì‹œë³´ë“œ ìƒì„±
from src.analysis.dashboard import DashboardGenerator, ExperimentSummary

dashboard = DashboardGenerator(output_dir="outputs/report")
summary = ExperimentSummary(
    experiment_name="My Experiment",
    timestamp="2024-11-27",
    total_frames=1000,
    species=["mouse", "dog"],
    presets_tested=["full", "standard", "minimal"],
)
dashboard.generate_full_dashboard(summary, gif_paths, plot_paths)
```

### Python ì›í´ë¦­ ìŠ¤í¬ë¦½íŠ¸ (`run_comprehensive.py`)

Shell ìŠ¤í¬ë¦½íŠ¸ ëŒ€ì‹  Python ìŠ¤í¬ë¦½íŠ¸ë¡œë„ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
# Quick test (debug mode, ~2 min)
python run_comprehensive.py --debug
python run_comprehensive.py -d

# Standard analysis (~10 min)
python run_comprehensive.py

# Full analysis with all species/presets (~25 min)
python run_comprehensive.py --all
python run_comprehensive.py -a

# Custom configuration
python run_comprehensive.py --species mouse,dog --presets full,standard,minimal
python run_comprehensive.py -s mouse,dog,horse -p full,standard -m 200

# Only generate visualizations from existing results
python run_comprehensive.py --visualize-only --input outputs/comprehensive/20241127_123456
```

**ì˜µì…˜:**

| ì˜µì…˜ | ë‹¨ì¶• | ì„¤ëª… |
|------|------|------|
| `--debug` | `-d` | Debug ëª¨ë“œ (50 frames, mouseë§Œ, ~2ë¶„) |
| `--all` | `-a` | Full ëª¨ë“œ (ëª¨ë“  ì¢…/í”„ë¦¬ì…‹, 300 frames, ~25ë¶„) |
| `--species` | `-s` | ì¢… ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„) |
| `--presets` | `-p` | í”„ë¦¬ì…‹ ëª©ë¡ (ì‰¼í‘œ êµ¬ë¶„) |
| `--max-frames` | `-m` | ìµœëŒ€ í”„ë ˆì„ ìˆ˜ |
| `--output` | `-o` | ì¶œë ¥ ë””ë ‰í† ë¦¬ |
| `--visualize-only` | | ì‹¤í—˜ ìŠ¤í‚µ, ì‹œê°í™”ë§Œ ìƒì„± |
| `--input` | `-i` | visualize-onlyìš© ì…ë ¥ ë””ë ‰í† ë¦¬ |

**ëª¨ë“œë³„ ì„¤ì •:**

| ëª¨ë“œ | Frames | Species | Presets | GIFs |
|------|--------|---------|---------|------|
| `debug` | 50 | mouse | full, minimal | No |
| `standard` | 200 | mouse, dog | full, standard, minimal | Yes |
| `full` | 300 | mouse, dog, horse | all 5 presets | Yes |

---

## Stage 4: Action Recognition Model Evaluation

ë”¥ëŸ¬ë‹ ê¸°ë°˜ í–‰ë™ ì¸ì‹ ëª¨ë¸ë“¤ì„ í‰ê°€í•˜ê³  ë¹„êµí•©ë‹ˆë‹¤.

### ì‹¤í–‰

```bash
# ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (~1ë¶„)
./run_evaluation.sh --debug

# í‘œì¤€ í‰ê°€ (~5ë¶„)
./run_evaluation.sh

# ì „ì²´ ë¶„ì„ (~15ë¶„)
./run_evaluation.sh --full

# í†µí•© ì‹¤í–‰ (í‚¤í¬ì¸íŠ¸ ì¶”ì¶œ + ëª¨ë¸ í‰ê°€)
./run_complete.sh --debug    # ~3ë¶„
./run_complete.sh            # ~15ë¶„
./run_complete.sh --full     # ~45ë¶„
```

### ì§€ì› ë°ì´í„°ì…‹ (Dual Label System)

| ë°ì´í„°ì…‹ | Label Type | í´ë˜ìŠ¤ | ìš©ë„ |
|----------|------------|--------|------|
| **locomotion_sample** | Locomotion | stationary, walking, running, other | ì´ë™ í–‰ë™ ë¶„ì„ |
| **mars_sample** | Social | other, attack, mount, investigation | ì‚¬íšŒì  ìƒí˜¸ì‘ìš© |

### ì§€ì› ëª¨ë¸

| ëª¨ë¸ | ì„¤ëª… | íŠ¹ì§• |
|------|------|------|
| **Rule-Based** | ì†ë„ ê¸°ë°˜ ê·œì¹™ ë¶„ë¥˜ | ë² ì´ìŠ¤ë¼ì¸, ë¹ ë¦„ |
| **MLP** | Multi-Layer Perceptron | í”„ë ˆì„ ë‹¨ìœ„ ë¶„ë¥˜ |
| **LSTM** | Long Short-Term Memory | ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ |
| **Transformer** | Self-Attention ê¸°ë°˜ | ì¥ê±°ë¦¬ ì˜ì¡´ì„± |

### í‚¤í¬ì¸íŠ¸ í”„ë¦¬ì…‹ë³„ í‰ê°€

| í”„ë¦¬ì…‹ | í‚¤í¬ì¸íŠ¸ ìˆ˜ | íŠ¹ì§• |
|--------|-------------|------|
| **full** | 27 | ëª¨ë“  í‚¤í¬ì¸íŠ¸, ìµœê³  ì •í™•ë„ |
| **minimal** | 3 | nose, tailbase, tailend |
| **locomotion** | 5 | ì´ë™ ë¶„ì„ ìµœì í™” |

### í‰ê°€ ê²°ê³¼ ì˜ˆì‹œ

```
Best Model: minimal_lstm
- Accuracy: 96.1%
- F1 Macro: 95.6%

Model Comparison (full keypoints):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Model       â”‚ Accuracy â”‚ F1      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ LSTM        â”‚ 95.3%    â”‚ 95.4%   â”‚
â”‚ MLP         â”‚ 92.7%    â”‚ 92.0%   â”‚
â”‚ Transformer â”‚ 82.8%    â”‚ 82.5%   â”‚
â”‚ Rule-Based  â”‚ 32.0%    â”‚ 12.1%   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì¶œë ¥ êµ¬ì¡°

```
outputs/evaluation/
â”œâ”€â”€ evaluation_results.json     # ì „ì²´ ê²°ê³¼ (JSON)
â”œâ”€â”€ models/                     # í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜
â”‚   â”œâ”€â”€ full_mlp.pt
â”‚   â”œâ”€â”€ full_lstm.pt
â”‚   â””â”€â”€ full_transformer.pt
â””â”€â”€ plots/                      # ì‹œê°í™”
    â””â”€â”€ confusion_matrices.png
```

---

## GitHub Repository

### ì €ì¥ì†Œ í´ë¡ 

```bash
git clone https://github.com/kafkapple/superanimal-behavior-poc.git
cd superanimal-behavior-poc
```

### ì œì™¸ë˜ëŠ” íŒŒì¼ (Git Ignored)

| ë””ë ‰í† ë¦¬/íŒŒì¼ | ì„¤ëª… | ìš©ëŸ‰ |
|---------------|------|------|
| `data/` | ì›ë³¸ ë¹„ë””ì˜¤, ë°ì´í„°ì…‹ | ~GB |
| `outputs/` | ì‹¤í—˜ ê²°ê³¼, ëª¨ë¸ | ~GB |
| `*.mp4, *.avi` | ë¹„ë””ì˜¤ íŒŒì¼ | Large |
| `*.h5, *.pt, *.pth` | í‚¤í¬ì¸íŠ¸, ëª¨ë¸ ê°€ì¤‘ì¹˜ | Large |
| `*.npy, *.npz` | NumPy ë°°ì—´ | Large |

### ì¬í˜„ì„ ìœ„í•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ

```bash
# í™˜ê²½ ì„¤ì¹˜ í›„
conda activate superanimal-poc

# ìƒ˜í”Œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ (ìë™)
python run.py --help  # ì²« ì‹¤í–‰ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ

# ë˜ëŠ” ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ
python -m src.scripts.download_samples
```

---

## ì°¸ê³  ìë£Œ

- [DeepLabCut ê³µì‹ ë¬¸ì„œ](https://deeplabcut.github.io/DeepLabCut/)
- [SuperAnimal Model Zoo](https://deeplabcut.github.io/DeepLabCut/docs/ModelZoo.html)
- [SuperAnimal ë…¼ë¬¸](https://www.nature.com/articles/s41467-024-48792-2)
- [MARS Dataset](https://neuroethology.github.io/MARS/) - Mouse Social Behavior
- [CalMS21 Dataset](https://data.caltech.edu/records/s0vdx-0k302) - Multi-Agent Behavior
- [AP-10K Dataset](https://github.com/AlexTheBad/AP-10K) - Animal Pose Benchmark
- [COCO Keypoints](https://cocodataset.org/) - Human Pose Benchmark

---

## ë¼ì´ì„ ìŠ¤

MIT License
